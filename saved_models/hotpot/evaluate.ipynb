{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions on HotpotQA\n",
    "- Model predicts weather a sentence is a supporting fact to answer a question\n",
    "- This notebook rearranges the predictions and evaluates the performance just like the hotpot evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickler(path,pkl_name,obj):\n",
    "    with open(os.path.join(path, pkl_name), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def unpickler(path,pkl_name):\n",
    "    with open(os.path.join(path, pkl_name) ,'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pkl_path = \"../../data/hotpot/\"\n",
    "data_pkl_name = \"preprocessed_dev.pkl\"\n",
    "predictions_pkl_path = \"./\"\n",
    "predictions_pkl_name = \"predictions.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = [[0,0],[0,1],[1,0],[1,1]]\n",
    "pred = [[1,1],[1,1],[1,0],[1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    num_correct = 0\n",
    "    for i in range(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            num_correct += 1\n",
    "    return num_correct/total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(gt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    assert(len(gt) != 0)\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    total_correct = 0\n",
    "    for i in trange(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            total_correct += 1\n",
    "        p = precision_score(gt[i], pred[i],average=\"binary\")\n",
    "        r = recall_score(gt[i], pred[i],average=\"binary\")\n",
    "        total_precision += p\n",
    "        total_recall += r\n",
    "        total_f1 += 2*(p*r)/(p+r) if (p+r)>0 else 0\n",
    "    return {\"precision\":total_precision/total_size, \"recall\":total_recall/total_size, \n",
    "            \"f1\":total_f1/total_size, \"em\":total_correct/total_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/home/bhargav/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "100%|██████████| 4/4 [00:00<00:00, 87.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.625, 'recall': 0.75, 'f1': 0.6666666666666666, 'em': 0.5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_predictions(predictions, document_lengths):\n",
    "    out_list = []\n",
    "    start_index = 0\n",
    "    for i in range(len(document_lengths)):\n",
    "        p = predictions[start_index:start_index+document_lengths[i]]\n",
    "        out_list.append(p)\n",
    "        start_index += document_lengths[i]\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reorganize_predictions(list(range(20)), [1,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = unpickler(data_pkl_path, data_pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequences', 'segment_ids', 'supporting_fact', 'document_lengths'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_raw = unpickler(predictions_pkl_path, predictions_pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306423,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.703494 ,  -7.3818617,  -9.597219 ,   4.442234 ,  -4.757165 ,\n",
       "        -2.452815 ,  -5.1548805, -11.324129 , -10.174879 ,  -7.2726355,\n",
       "        -8.698872 ,  -4.4058604,  -2.4269946,  -6.133337 ,  -5.7811146,\n",
       "        -3.2419255,   3.4809365,  -9.175812 ,  -9.545071 ,  -7.4124694],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.612978"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.374624"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer_labels = (torch.sigmoid(torch.tensor(predictions_raw)) > 0.9).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20152"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_answer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer_labels_reorganized = reorganize_predictions(pred_answer_labels, dataset[\"document_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7404"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_answer_labels_reorganized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_reorganized = reorganize_predictions(dataset[\"supporting_fact\"], dataset[\"document_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7404"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_reorganized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the lengths same ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gt_reorganized)):\n",
    "    assert(len(gt_reorganized[i]) == len(pred_answer_labels_reorganized[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18001"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset[\"supporting_fact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20152"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_answer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7404/7404 [00:13<00:00, 557.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6867104762921196,\n",
       " 'recall': 0.7088041213243822,\n",
       " 'f1': 0.6588673467117654,\n",
       " 'em': 0.228795245813074}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gt_reorganized, pred_answer_labels_reorganized)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num 1 in GT:18001\n",
    "\n",
    "====================================================\n",
    "no dropout, first 'n' negative examples\n",
    "====================================================\n",
    "Threshold = 0.9\n",
    "num 1 in pred:23898\n",
    "{'precision': 0.6334376802482,\n",
    " 'recall': 0.7238360538704973,\n",
    " 'f1': 0.6292228317433969,\n",
    " 'em': 0.1963803349540789}\n",
    "====================================================\n",
    "Threshold = 0.5\n",
    "num 1 in pred:53597\n",
    "{'precision': 0.41854551203917234,\n",
    " 'recall': 0.9118060379203041,\n",
    " 'f1': 0.5307264706450345,\n",
    " 'em': 0.07806591031874663}\n",
    "====================================================\n",
    "0.1 dropout, random negative examples\n",
    "====================================================\n",
    "Threshold = 0.5\n",
    "num 1 in pred:44856\n",
    "{'precision': 0.46638407446220137,\n",
    " 'recall': 0.9064059646008644,\n",
    " 'f1': 0.5776555929156273,\n",
    " 'em': 0.10386277687736359}\n",
    "====================================================\n",
    "Threshold = 0.9\n",
    "num 1 in pred:20152\n",
    "{'precision': 0.6867104762921196,\n",
    " 'recall': 0.7088041213243822,\n",
    " 'f1': 0.6588673467117654,\n",
    " 'em': 0.228795245813074}\n",
    "====================================================\n",
    "====================================================\n",
    "====================================================\n",
    "====================================================\n",
    "====================================================\n",
    "===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
