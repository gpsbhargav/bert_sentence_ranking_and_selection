{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions on HotpotQA\n",
    "- Model predicts weather a sentence is a supporting fact to answer a question\n",
    "- This notebook rearranges the predictions and evaluates the performance just like the hotpot evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickler(path,pkl_name,obj):\n",
    "    with open(os.path.join(path, pkl_name), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def unpickler(path,pkl_name):\n",
    "    with open(os.path.join(path, pkl_name) ,'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pkl_path = \"../../data/hotpot/\"\n",
    "data_pkl_name = \"preprocessed_dev.pkl\"\n",
    "predictions_pkl_path = \"./\"\n",
    "predictions_pkl_name = \"predictions.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    num_correct = 0\n",
    "    for i in range(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            num_correct += 1\n",
    "    return num_correct/total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    assert(len(gt) != 0)\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    total_correct = 0\n",
    "    for i in trange(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            total_correct += 1\n",
    "        p = precision_score(gt[i], pred[i],average=\"binary\")\n",
    "        r = recall_score(gt[i], pred[i],average=\"binary\")\n",
    "        total_precision += p\n",
    "        total_recall += r\n",
    "        total_f1 += 2*(p*r)/(p+r) if (p+r)>0 else 0\n",
    "    return {\"precision\":total_precision/total_size, \"recall\":total_recall/total_size, \n",
    "            \"f1\":total_f1/total_size, \"em\":total_correct/total_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_predictions(predictions, document_lengths):\n",
    "    out_list = []\n",
    "    start_index = 0\n",
    "    for i in range(len(document_lengths)):\n",
    "        p = predictions[start_index:start_index+document_lengths[i]]\n",
    "        out_list.append(p)\n",
    "        start_index += document_lengths[i]\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = unpickler(data_pkl_path, data_pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequences', 'segment_ids', 'supporting_fact', 'document_lengths'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_raw = unpickler(predictions_pkl_path, predictions_pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306423,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.703494 ,  -7.3818617,  -9.597219 ,   4.442234 ,  -4.757165 ,\n",
       "        -2.452815 ,  -5.1548805, -11.324129 , -10.174879 ,  -7.2726355,\n",
       "        -8.698872 ,  -4.4058604,  -2.4269946,  -6.133337 ,  -5.7811146,\n",
       "        -3.2419255,   3.4809365,  -9.175812 ,  -9.545071 ,  -7.4124694],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.612978"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.374624"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.9396749"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer_labels = (torch.sigmoid(torch.tensor(predictions_raw)) > threshold).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(pred_answer_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20152"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_answer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer_labels_reorganized = reorganize_predictions(pred_answer_labels, dataset[\"document_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7404"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_answer_labels_reorganized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_reorganized = reorganize_predictions(dataset[\"supporting_fact\"], dataset[\"document_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7404"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_reorganized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the lengths same ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gt_reorganized)):\n",
    "    assert(len(gt_reorganized[i]) == len(pred_answer_labels_reorganized[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset[\"supporting_fact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_answer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7404 [00:00<?, ?it/s]/home/bhargav/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|██████████| 7404/7404 [00:13<00:00, 565.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6867104762921196,\n",
       " 'recall': 0.7088041213243822,\n",
       " 'f1': 0.6588673467117654,\n",
       " 'em': 0.228795245813074}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gt_reorganized, pred_answer_labels_reorganized)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num 1 in GT:18001\n",
    "\n",
    "====================================================\n",
    "no dropout, first 'n' negative examples\n",
    "====================================================\n",
    "Threshold = 0.9\n",
    "num 1 in pred:23898\n",
    "{'precision': 0.6334376802482,\n",
    " 'recall': 0.7238360538704973,\n",
    " 'f1': 0.6292228317433969,\n",
    " 'em': 0.1963803349540789}\n",
    "====================================================\n",
    "Threshold = 0.5\n",
    "num 1 in pred:53597\n",
    "{'precision': 0.41854551203917234,\n",
    " 'recall': 0.9118060379203041,\n",
    " 'f1': 0.5307264706450345,\n",
    " 'em': 0.07806591031874663}\n",
    "====================================================\n",
    "0.1 dropout, random negative examples\n",
    "====================================================\n",
    "Threshold = 0.5\n",
    "num 1 in pred:44856\n",
    "{'precision': 0.46638407446220137,\n",
    " 'recall': 0.9064059646008644,\n",
    " 'f1': 0.5776555929156273,\n",
    " 'em': 0.10386277687736359}\n",
    "====================================================\n",
    "Threshold = 0.9\n",
    "num 1 in pred:20152\n",
    "{'precision': 0.6867104762921196,\n",
    " 'recall': 0.7088041213243822,\n",
    " 'f1': 0.6588673467117654,\n",
    " 'em': 0.228795245813074}\n",
    "====================================================\n",
    "====================================================\n",
    "====================================================\n",
    "====================================================\n",
    "====================================================\n",
    "===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of correct and incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e9d394240>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot((torch.sigmoid(torch.tensor(predictions_raw))).numpy(),kde=False, hist=True, rug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for individual question sentence pairs\n",
    "wrong_prediction_indices = []\n",
    "correct_prediction_indices = []\n",
    "for i in range(len(dataset[\"supporting_fact\"])):\n",
    "    if( dataset[\"supporting_fact\"][i] != pred_answer_labels[i]):\n",
    "        wrong_prediction_indices.append(i)\n",
    "    else:\n",
    "        correct_prediction_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13539"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_prediction_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292884"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_prediction_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_s_pair(index, dataset):\n",
    "    token_ids = dataset[\"sequences\"][index]\n",
    "    true_label = dataset[\"supporting_fact\"][index]\n",
    "    words = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    return {\"sequence\":\" \".join(words),\"true_label\":true_label} \n",
    "\n",
    "def sort_indices_increasing_confidence(indices, scores, threshold):\n",
    "    margins = []\n",
    "    for index in indices:\n",
    "        m = scores[index] - threshold\n",
    "        margins.append(m)\n",
    "    return np.argsort(np.absolute(margins)), np.absolute(margins)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] what science fantasy young adult series , told in first person , has a set of companion books na ##rra ##ting the stories of enslaved worlds and alien species ? [SEP] with respect to continuity within the series , it takes place before book # 23 , \" the pretend ##er \" , although the events told in the story occur between the time of \" the el ##lim ##ist chronicles \" and \" the and ##ali ##te chronicles \" . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(wrong_prediction_indices[1], dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least and most confident wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_scores = (torch.sigmoid(torch.tensor(predictions_raw))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_confidences_sorted, incorrect_margins = sort_indices_increasing_confidence(wrong_prediction_indices, sigmoid_scores, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] which direction do both the m1 and the m ##6 motorway ##s travel ? [SEP] the a1 ##4 is a major road in england , running 127 mi from the port of felix ##sto ##we , suffolk to the cat ##thorpe interchange at the junction of the m1 and m ##6 motorway ##s near rugby , warwickshire . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 0}\n",
      "margin:  9.63211059568092e-06\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(wrong_prediction_indices[incorrect_confidences_sorted[0]], dataset))\n",
    "print(\"margin: \",incorrect_margins[incorrect_confidences_sorted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] for which film did the director team with nasa scientists , aliens of the deep or poetry in motion ? [SEP] an extended cd - rom version was also released . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 1}\n",
      "margin:  0.8999674147220503\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(wrong_prediction_indices[incorrect_confidences_sorted[-1]], dataset))\n",
    "print(\"margin: \",incorrect_margins[incorrect_confidences_sorted[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least and most confident correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_confidences_sorted, correct_margins = sort_indices_increasing_confidence(correct_prediction_indices, sigmoid_scores, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] in which movie the stephanie kay pan ##aba ##ker was alongside with her elder sister danielle nicole pan ##aba ##ker ? [SEP] she is the younger sister of danielle pan ##aba ##ker . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 0}\n",
      "margin:  2.4580955505393298e-05\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(correct_prediction_indices[correct_confidences_sorted[0]], dataset))\n",
    "print(\"margin: \",correct_margins[correct_confidences_sorted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] what year was the american healthy lifestyle magazine , in which georgia rick ##ard contributed , started ? [SEP] the village has a very healthy sex ratio of 99 ##7 : 1000 , which means villagers do not follow discrimination of a girl from a boy . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 0}\n",
      "margin:  0.8999999917493838\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(correct_prediction_indices[correct_confidences_sorted[-1]], dataset))\n",
    "print(\"margin: \",correct_margins[correct_confidences_sorted[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
