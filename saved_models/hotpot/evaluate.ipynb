{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions on HotpotQA\n",
    "- Model predicts weather a sentence is a supporting fact to answer a question\n",
    "- This notebook rearranges the predictions and evaluates the performance just like the hotpot evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickler(path,pkl_name,obj):\n",
    "    with open(os.path.join(path, pkl_name), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def unpickler(path,pkl_name):\n",
    "    with open(os.path.join(path, pkl_name) ,'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pkl_path = \"../../data/hotpot/\"\n",
    "data_pkl_name = \"preprocessed_dev.pkl\"\n",
    "predictions_pkl_path = \"./\"\n",
    "predictions_pkl_name = \"predictions_2x.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    num_correct = 0\n",
    "    for i in range(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            num_correct += 1\n",
    "    return num_correct/total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    assert(len(gt) != 0)\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    total_correct = 0\n",
    "    for i in trange(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            total_correct += 1\n",
    "        p = precision_score(gt[i], pred[i],average=\"binary\")\n",
    "        r = recall_score(gt[i], pred[i],average=\"binary\")\n",
    "        total_precision += p\n",
    "        total_recall += r\n",
    "        total_f1 += 2*(p*r)/(p+r) if (p+r)>0 else 0\n",
    "    return {\"precision\":total_precision/total_size, \"recall\":total_recall/total_size, \n",
    "            \"f1\":total_f1/total_size, \"em\":total_correct/total_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_predictions(predictions, document_lengths):\n",
    "    out_list = []\n",
    "    start_index = 0\n",
    "    for i in range(len(document_lengths)):\n",
    "        p = predictions[start_index:start_index+document_lengths[i]]\n",
    "        out_list.append(p)\n",
    "        start_index += document_lengths[i]\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = unpickler(data_pkl_path, data_pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequences', 'segment_ids', 'supporting_fact', 'document_lengths'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_raw = unpickler(predictions_pkl_path, predictions_pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306423,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.5536017, -6.9522686, -7.0652246,  6.3503833, -6.1533966,\n",
       "       -5.8135967, -7.0851107, -7.021992 , -7.185976 , -7.3964677,\n",
       "       -7.29731  , -5.8978343, -6.055974 , -6.916958 , -6.894326 ,\n",
       "       -5.8755207,  6.730695 , -7.031531 , -7.1481214, -6.9699774],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.6060705"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3882093"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.7001832"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer_labels = (torch.sigmoid(torch.tensor(predictions_raw)) > threshold).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(pred_answer_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21173"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_answer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer_labels_reorganized = reorganize_predictions(pred_answer_labels, dataset[\"document_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7404"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_answer_labels_reorganized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_reorganized = reorganize_predictions(dataset[\"supporting_fact\"], dataset[\"document_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7404"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_reorganized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the lengths same ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gt_reorganized)):\n",
    "    assert(len(gt_reorganized[i]) == len(pred_answer_labels_reorganized[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18001"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset[\"supporting_fact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21173"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_answer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 59/7404 [00:00<00:12, 586.21it/s]/home/bhargav/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|██████████| 7404/7404 [00:13<00:00, 561.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6847269321810139,\n",
       " 'recall': 0.7458830169020635,\n",
       " 'f1': 0.6779622093512215,\n",
       " 'em': 0.24108589951377635}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gt_reorganized, pred_answer_labels_reorganized)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num 1 in GT:18001\n",
    "\n",
    "====================================================\n",
    "no dropout, first 'n' negative examples\n",
    "====================================================\n",
    "Threshold = 0.9\n",
    "num 1 in pred:23898\n",
    "{'precision': 0.6334376802482,\n",
    " 'recall': 0.7238360538704973,\n",
    " 'f1': 0.6292228317433969,\n",
    " 'em': 0.1963803349540789}\n",
    "====================================================\n",
    "Threshold = 0.5\n",
    "num 1 in pred:53597\n",
    "{'precision': 0.41854551203917234,\n",
    " 'recall': 0.9118060379203041,\n",
    " 'f1': 0.5307264706450345,\n",
    " 'em': 0.07806591031874663}\n",
    "====================================================\n",
    "0.1 dropout, random negative examples\n",
    "====================================================\n",
    "Threshold = 0.5\n",
    "num 1 in pred:44856\n",
    "{'precision': 0.46638407446220137,\n",
    " 'recall': 0.9064059646008644,\n",
    " 'f1': 0.5776555929156273,\n",
    " 'em': 0.10386277687736359}\n",
    "====================================================\n",
    "Threshold = 0.9\n",
    "num 1 in pred:20152\n",
    "{'precision': 0.6867104762921196,\n",
    " 'recall': 0.7088041213243822,\n",
    " 'f1': 0.6588673467117654,\n",
    " 'em': 0.228795245813074}\n",
    "====================================================\n",
    "0.1 dropout, 2x positive, equal number of negative\n",
    "====================================================\n",
    "Threshold = 0.95\n",
    "num 1 in pred: 21173\n",
    "{'precision': 0.6847269321810139,\n",
    " 'recall': 0.7458830169020635,\n",
    " 'f1': 0.6779622093512215,\n",
    " 'em': 0.24108589951377635}\n",
    "====================================================\n",
    "====================================================\n",
    "====================================================\n",
    "===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of correct and incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhargav/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f861f1dfba8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFfBJREFUeJzt3X+s3fV93/Hnq3bJ0jUUEi4RwngmmVOVoM0BK3iqkqWhIQZNMZlIZ9IWJ0NzQmFa12oKWf8gyg8paZVFQ0rISLEwVflV0hSrckYRZWWbgHAplAAJ84VQuMECBwjNREdm8t4f5+PsYM71/fie63t88fMhHZ3veX8/n+/5fLjXvPz9fL/nOFWFJEk9fmbSA5AkLR+GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkbisnPYDFdtxxx9WaNWsmPQxJWlbuvffeH1TV1HztXnOhsWbNGqanpyc9DElaVpL8bU87l6ckSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3V5znwgfx7V3PzGy/uEzVi/xSCTp8OSZhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6zRsaSbYleSbJg0O1G5Lc3x6PJ7m/1dck+fuhfV8d6nN6km8nmUlyeZK0+huT3JpkV3s+ttXT2s0keSDJaYs/fUnSweg507ga2DhcqKp/VVXrqmod8HXgT4d2P7pvX1V9fKh+BbAVWNse+455KXBbVa0FbmuvAc4earu19ZckTdC8oVFVdwDPjdrXzhZ+DbjuQMdIcgJwdFXdWVUFXAOc23ZvAra37e371a+pgbuAY9pxJEkTMu41jXcBT1fVrqHayUnuS/JXSd7VaicCs0NtZlsN4M1VtRugPR8/1OfJOfq8QpKtSaaTTO/Zs2e8GUmS5jRuaJzPK88ydgOrq+odwO8A1yY5GsiIvjXPsbv7VNWVVbW+qtZPTU11DFuStBAL/keYkqwE/iVw+r5aVb0EvNS2703yKPA2BmcJq4a6rwKeattPJzmhqna35adnWn0WOGmOPpKkCRjnTONXge9W1U+XnZJMJVnRtt/C4CL2Y23Z6UdJNrTrIBcAN7duO4AtbXvLfvUL2l1UG4AX9i1jSZImo+eW2+uAO4FfTDKb5MK2azOvvgD+buCBJH8D3AR8vKr2XUS/CPhDYAZ4FPhmq38eeF+SXcD72muAncBjrf3XgN86+OlJkhbTvMtTVXX+HPWPjKh9ncEtuKPaTwOnjqg/C5w5ol7AxfONT5K0dPxEuCSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnq1vNvhG9L8kySB4dqn0ry/ST3t8c5Q/s+mWQmySNJ3j9U39hqM0kuHaqfnOTuJLuS3JDkqFZ/XXs90/avWaxJS5IWpudM42pg44j6l6pqXXvsBEhyCrAZeHvr85UkK5KsAL4MnA2cApzf2gJ8oR1rLfA8cGGrXwg8X1X/GPhSaydJmqB5Q6Oq7gCe6zzeJuD6qnqpqr4HzADvbI+Zqnqsqn4MXA9sShLgvcBNrf924NyhY21v2zcBZ7b2kqQJGeeaxiVJHmjLV8e22onAk0NtZlttrvqbgB9W1d796q84Vtv/QmsvSZqQhYbGFcBbgXXAbuCLrT7qTKAWUD/QsV4lydYk00mm9+zZc6BxS5LGsKDQqKqnq+rlqvoJ8DUGy08wOFM4aajpKuCpA9R/AByTZOV+9Vccq+3/BeZYJquqK6tqfVWtn5qaWsiUJEkdFhQaSU4YevlBYN+dVTuAze3Op5OBtcC3gHuAte1OqaMYXCzfUVUF3A6c1/pvAW4eOtaWtn0e8JetvSRpQlbO1yDJdcB7gOOSzAKXAe9Jso7BctHjwMcAquqhJDcCDwN7gYur6uV2nEuAW4AVwLaqeqi9xSeA65N8FrgPuKrVrwL+KMkMgzOMzWPPVpI0lrzW/vK+fv36mp6eXlDfa+9+YmT9w2esHmdIknTYS3JvVa2fr52fCJckdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3eYNjSTbkjyT5MGh2h8k+W6SB5J8I8kxrb4myd8nub89vjrU5/Qk304yk+TyJGn1Nya5Ncmu9nxsq6e1m2nvc9riT1+SdDB6zjSuBjbuV7sVOLWq/gnwv4BPDu17tKrWtcfHh+pXAFuBte2x75iXArdV1VrgtvYa4Oyhtltbf0nSBM0bGlV1B/DcfrW/qKq97eVdwKoDHSPJCcDRVXVnVRVwDXBu270J2N62t+9Xv6YG7gKOaceRJE3IYlzT+NfAN4den5zkviR/leRdrXYiMDvUZrbVAN5cVbsB2vPxQ32enKOPJGkCVo7TOcnvAXuBP26l3cDqqno2yenAnyV5O5AR3Wu+w/f2SbKVwRIWq1ev7hm6JGkBFnymkWQL8C+AX29LTlTVS1X1bNu+F3gUeBuDs4ThJaxVwFNt++l9y07t+ZlWnwVOmqPPK1TVlVW1vqrWT01NLXRKkqR5LCg0kmwEPgF8oKpeHKpPJVnRtt/C4CL2Y23Z6UdJNrS7pi4Abm7ddgBb2vaW/eoXtLuoNgAv7FvGkiRNxrzLU0muA94DHJdkFriMwd1SrwNubXfO3tXulHo38Okke4GXgY9X1b6L6BcxuBPr9Qyugey7DvJ54MYkFwJPAB9q9Z3AOcAM8CLw0XEmKkka37yhUVXnjyhfNUfbrwNfn2PfNHDqiPqzwJkj6gVcPN/4JElLx0+ES5K6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqVtXaCTZluSZJA8O1d6Y5NYku9rzsa2eJJcnmUnyQJLThvpsae13JdkyVD89ybdbn8uT5EDvIUmajN4zjauBjfvVLgVuq6q1wG3tNcDZwNr22ApcAYMAAC4DzgDeCVw2FAJXtLb7+m2c5z0kSRPQFRpVdQfw3H7lTcD2tr0dOHeofk0N3AUck+QE4P3ArVX1XFU9D9wKbGz7jq6qO6uqgGv2O9ao95AkTcA41zTeXFW7Adrz8a1+IvDkULvZVjtQfXZE/UDv8QpJtiaZTjK9Z8+eMaYkSTqQQ3EhPCNqtYB6t6q6sqrWV9X6qampg+kqSToI44TG021pifb8TKvPAicNtVsFPDVPfdWI+oHeQ5I0AeOExg5g3x1QW4Cbh+oXtLuoNgAvtKWlW4CzkhzbLoCfBdzS9v0oyYZ219QF+x1r1HtIkiZgZU+jJNcB7wGOSzLL4C6ozwM3JrkQeAL4UGu+EzgHmAFeBD4KUFXPJfkMcE9r9+mq2ndx/SIGd2i9Hvhme3CA95AkTUBXaFTV+XPsOnNE2wIunuM424BtI+rTwKkj6s+Oeg9J0mT4iXBJUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1G3BoZHkF5PcP/T4uyS/neRTSb4/VD9nqM8nk8wkeSTJ+4fqG1ttJsmlQ/WTk9ydZFeSG5IctfCpSpLGteDQqKpHqmpdVa0DTgdeBL7Rdn9p376q2gmQ5BRgM/B2YCPwlSQrkqwAvgycDZwCnN/aAnyhHWst8Dxw4ULHK0ka32ItT50JPFpVf3uANpuA66vqpar6HjADvLM9Zqrqsar6MXA9sClJgPcCN7X+24FzF2m8kqQFWKzQ2AxcN/T6kiQPJNmW5NhWOxF4cqjNbKvNVX8T8MOq2rtfXZI0IWOHRrvO8AHgT1rpCuCtwDpgN/DFfU1HdK8F1EeNYWuS6STTe/bsOYjRS5IOxmKcaZwN/HVVPQ1QVU9X1ctV9RPgawyWn2BwpnDSUL9VwFMHqP8AOCbJyv3qr1JVV1bV+qpaPzU1tQhTkiSNshihcT5DS1NJThja90Hgwba9A9ic5HVJTgbWAt8C7gHWtjuljmKw1LWjqgq4HTiv9d8C3LwI45UkLdDK+ZvMLcnPAe8DPjZU/v0k6xgsJT2+b19VPZTkRuBhYC9wcVW93I5zCXALsALYVlUPtWN9Arg+yWeB+4CrxhmvJGk8Y4VGVb3I4IL1cO03D9D+c8DnRtR3AjtH1B/j/y9vSZImzE+ES5K6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuY4dGkseTfDvJ/UmmW+2NSW5Nsqs9H9vqSXJ5kpkkDyQ5beg4W1r7XUm2DNVPb8efaX0z7pglSQuzWGcav1JV66pqfXt9KXBbVa0FbmuvAc4G1rbHVuAKGIQMcBlwBoN/E/yyfUHT2mwd6rdxkcYsSTpIh2p5ahOwvW1vB84dql9TA3cBxyQ5AXg/cGtVPVdVzwO3AhvbvqOr6s6qKuCaoWNJkpbYYoRGAX+R5N4kW1vtzVW1G6A9H9/qJwJPDvWdbbUD1WdH1CVJE7ByEY7xy1X1VJLjgVuTfPcAbUddj6gF1F950EFYbQVYvXr1/COWJC3I2GcaVfVUe34G+AaDaxJPt6Ul2vMzrfkscNJQ91XAU/PUV42o7z+GK6tqfVWtn5qaGndKkqQ5jBUaSf5hkjfs2wbOAh4EdgD77oDaAtzctncAF7S7qDYAL7Tlq1uAs5Ic2y6AnwXc0vb9KMmGdtfUBUPHkiQtsXGXp94MfKPdBbsSuLaq/muSe4Abk1wIPAF8qLXfCZwDzAAvAh8FqKrnknwGuKe1+3RVPde2LwKuBl4PfLM9JEkTMFZoVNVjwD8dUX8WOHNEvYCL5zjWNmDbiPo0cOo445QkLQ4/ES5J6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuCw6NJCcluT3Jd5I8lOTftfqnknw/yf3tcc5Qn08mmUnySJL3D9U3ttpMkkuH6icnuTvJriQ3JDlqoeOVJI1vnDONvcDvVtUvARuAi5Oc0vZ9qarWtcdOgLZvM/B2YCPwlSQrkqwAvgycDZwCnD90nC+0Y60FngcuHGO8kqQxLTg0qmp3Vf112/4R8B3gxAN02QRcX1UvVdX3gBngne0xU1WPVdWPgeuBTUkCvBe4qfXfDpy70PFKksa3KNc0kqwB3gHc3UqXJHkgybYkx7baicCTQ91mW22u+puAH1bV3v3qo95/a5LpJNN79uxZhBlJkkYZOzSS/DzwdeC3q+rvgCuAtwLrgN3AF/c1HdG9FlB/dbHqyqpaX1Xrp6amDnIGkqReK8fpnORnGQTGH1fVnwJU1dND+78G/Hl7OQucNNR9FfBU2x5V/wFwTJKV7WxjuL0kaQLGuXsqwFXAd6rqPw3VTxhq9kHgwba9A9ic5HVJTgbWAt8C7gHWtjuljmJwsXxHVRVwO3Be678FuHmh45UkjW+cM41fBn4T+HaS+1vtPzK4+2kdg6Wkx4GPAVTVQ0luBB5mcOfVxVX1MkCSS4BbgBXAtqp6qB3vE8D1ST4L3McgpCRJE7Lg0Kiq/8Ho6w47D9Dnc8DnRtR3jupXVY8xuLtKknQY8BPhkqRuhoYkqZuhIUnqNtYtt0eKa+9+YmT9w2esXuKRSNJkeaYhSepmaEiSurk8JUnLzCSXzD3TkCR1MzQkSd0MDUlSN0NDktTN0JAkdfPuqTHMdQcD+ME/Sa9NnmlIkroZGpKkbi5PHSJ+X5Wk1yJDQ5IOQwe6ZjpJhsYS8wxE0nJ22IdGko3Af2bw74f/YVV9fsJDOiQME+nIdLieUczlsA6NJCuALwPvA2aBe5LsqKqHJzuypbNYv1CGj7Q0llsIHKzDOjSAdwIzVfUYQJLrgU3AERMai2U5/SIbcFoMy+l3fjk53EPjRODJodezwBkTGouWiH/YpcPX4R4aGVGrVzVKtgJb28v/neSRBb7fccAPFth3uXLORwbnfAT49fHm/I96Gh3uoTELnDT0ehXw1P6NqupK4Mpx3yzJdFWtH/c4y4lzPjI45yPDUsz5cP9E+D3A2iQnJzkK2AzsmPCYJOmIdVifaVTV3iSXALcwuOV2W1U9NOFhSdIR67AODYCq2gnsXKK3G3uJaxlyzkcG53xkOORzTtWrritLkjTS4X5NQ5J0GDkiQyPJxiSPJJlJcumI/a9LckPbf3eSNUs/ysXVMeffSfJwkgeS3Jak6/a7w9l8cx5qd16SSrLs77TpmXOSX2s/64eSXLvUY1xsHb/bq5PcnuS+9vt9ziTGuViSbEvyTJIH59ifJJe3/x4PJDltUQdQVUfUg8EF9UeBtwBHAX8DnLJfm98Cvtq2NwM3THrcSzDnXwF+rm1fdCTMubV7A3AHcBewftLjXoKf81rgPuDY9vr4SY97CeZ8JXBR2z4FeHzS4x5zzu8GTgMenGP/OcA3GXzObQNw92K+/5F4pvHTryapqh8D+76aZNgmYHvbvgk4M8moDxouF/POuapur6oX28u7GHwmZjnr+TkDfAb4feD/LOXgDpGeOf8b4MtV9TxAVT2zxGNcbD1zLuDotv0LjPis13JSVXcAzx2gySbgmhq4CzgmyQmL9f5HYmiM+mqSE+dqU1V7gReANy3J6A6NnjkPu5DB31SWs3nnnOQdwElV9edLObBDqOfn/DbgbUn+Z5K72rdIL2c9c/4U8BtJZhnciflvl2ZoE3Owf94PymF/y+0h0PPVJF1fX7KMdM8nyW8A64F/fkhHdOgdcM5Jfgb4EvCRpRrQEuj5Oa9ksET1HgZnk/89yalV9cNDPLZDpWfO5wNXV9UXk/wz4I/anH9y6Ic3EYf0/19H4plGz1eT/LRNkpUMTmkPdDp4uOv6OpYkvwr8HvCBqnppicZ2qMw35zcApwL/LcnjDNZ+dyzzi+G9v9s3V9X/rarvAY8wCJHlqmfOFwI3AlTVncA/YPAdTa9VXX/eF+pIDI2erybZAWxp2+cBf1ntCtMyNe+c21LNf2EQGMt9nRvmmXNVvVBVx1XVmqpaw+A6zgeqanoyw10UPb/bf8bgpgeSHMdgueqxJR3l4uqZ8xPAmQBJfolBaOxZ0lEurR3ABe0uqg3AC1W1e7EOfsQtT9UcX02S5NPAdFXtAK5icAo7w+AMY/PkRjy+zjn/AfDzwJ+0a/5PVNUHJjboMXXO+TWlc863AGcleRh4GfgPVfXs5EY9ns45/y7wtST/nsEyzUeW818Ck1zHYHnxuHad5jLgZwGq6qsMrtucA8wALwIfXdT3X8b/7SRJS+xIXJ6SJC2QoSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRu/w/tlCw4tyUwzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot((torch.sigmoid(torch.tensor(predictions_raw))).numpy(),kde=False, hist=True, rug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for individual question sentence pairs\n",
    "wrong_prediction_indices = []\n",
    "correct_prediction_indices = []\n",
    "for i in range(len(dataset[\"supporting_fact\"])):\n",
    "    if( dataset[\"supporting_fact\"][i] != pred_answer_labels[i]):\n",
    "        wrong_prediction_indices.append(i)\n",
    "    else:\n",
    "        correct_prediction_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13186"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_prediction_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293237"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_prediction_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_s_pair(index, dataset):\n",
    "    token_ids = dataset[\"sequences\"][index]\n",
    "    true_label = dataset[\"supporting_fact\"][index]\n",
    "    words = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    return {\"sequence\":\" \".join(words),\"true_label\":true_label} \n",
    "\n",
    "def sort_indices_increasing_confidence(indices, scores, threshold):\n",
    "    margins = []\n",
    "    for index in indices:\n",
    "        m = scores[index] - threshold\n",
    "        margins.append(m)\n",
    "    return np.argsort(np.absolute(margins)), np.absolute(margins)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] what science fantasy young adult series , told in first person , has a set of companion books na ##rra ##ting the stories of enslaved worlds and alien species ? [SEP] with respect to continuity within the series , it takes place before book # 23 , \" the pretend ##er \" , although the events told in the story occur between the time of \" the el ##lim ##ist chronicles \" and \" the and ##ali ##te chronicles \" . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(wrong_prediction_indices[1], dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least and most confident wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_scores = (torch.sigmoid(torch.tensor(predictions_raw))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_confidences_sorted, incorrect_margins = sort_indices_increasing_confidence(wrong_prediction_indices, sigmoid_scores, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] chicago ##land sports hall of fame was founded by the company located in what washington town , near the state capital ? [SEP] founded in 1896 by leopold fried ##eric ##h schmidt , it was bought by g . he ##ile ##man brewing company in 1983 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 0}\n",
      "margin:  6.5445899963822995e-06\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(wrong_prediction_indices[incorrect_confidences_sorted[0]], dataset))\n",
    "print(\"margin: \",incorrect_margins[incorrect_confidences_sorted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] what country does washington dull ##es international airport and baltimore – washington metropolitan area have in common ? [SEP] according to an ancient hawaiian story a local woman compared her husband \\' s cruelty to the sharp edge of cutting bamboo ; thus the place was named kane ##ʻ oh ##e or \" bamboo man \" . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 1}\n",
      "margin:  0.9491464490303769\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(wrong_prediction_indices[incorrect_confidences_sorted[-1]], dataset))\n",
    "print(\"margin: \",incorrect_margins[incorrect_confidences_sorted[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least and most confident correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_confidences_sorted, correct_margins = sort_indices_increasing_confidence(correct_prediction_indices, sigmoid_scores, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] edo ##ardo sole ##ri is playing on loan from which italian football club ? [SEP] ass ##oc ##ia ##zione cal ##cio milan is an italian football club based in milan , lombardy . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 0}\n",
      "margin:  7.76052474971145e-06\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(correct_prediction_indices[correct_confidences_sorted[0]], dataset))\n",
    "print(\"margin: \",correct_margins[correct_confidences_sorted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '[CLS] are harry ki ##zi ##rian and howard kazan ##jian known for the same industry ? [SEP] it is assumed that the previous communities of salmon cove and jerry ’ s cove became the community of harry ’ s harbour . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'true_label': 0}\n",
      "margin:  0.94950282467762\n"
     ]
    }
   ],
   "source": [
    "print(get_q_s_pair(correct_prediction_indices[correct_confidences_sorted[-1]], dataset))\n",
    "print(\"margin: \",correct_margins[correct_confidences_sorted[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
