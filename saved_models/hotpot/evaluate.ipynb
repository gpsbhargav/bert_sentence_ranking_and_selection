{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions on HotpotQA\n",
    "- Model predicts weather a sentence is a supporting fact to answer a question\n",
    "- This notebook rearranges the predictions and evaluates the performance just like the hotpot evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = [[0,0],[0,1],[1,0],[1,1]]\n",
    "pred = [[1,1],[1,1],[1,0],[1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    num_correct = 0\n",
    "    for i in range(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            num_correct += 1\n",
    "    return num_correct/total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(gt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gt, pred):\n",
    "    assert(len(gt) == len(pred))\n",
    "    total_size = len(pred)\n",
    "    assert(len(gt) != 0)\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    total_correct = 0\n",
    "    for i in range(total_size):\n",
    "        if(gt[i] == pred[i]):\n",
    "            total_correct += 1\n",
    "        p = precision_score(gt[i], pred[i],average=\"binary\")\n",
    "        r = recall_score(gt[i], pred[i],average=\"binary\")\n",
    "        total_precision += p\n",
    "        total_recall += r\n",
    "        total_f1 += 2*(p*r)/(p+r) if (p+r)>0 else 0\n",
    "    return total_precision/total_size, total_recall/total_size, total_f1/total_size, total_correct/total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhargav/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.625, 0.75, 0.6666666666666666, 0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_predictions(predictions, document_lengths):\n",
    "    out_list = []\n",
    "    start_index = 0\n",
    "    for i in range(len(document_lengths)):\n",
    "        p = predictions[start_index:start_index+document_lengths[i]]\n",
    "        out_list.append(p)\n",
    "        start_index += document_lengths[i]\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reorganize_predictions(list(range(20)), [1,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
